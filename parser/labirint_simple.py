#!/usr/bin/env python3
"""–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä –±–µ–∑ Selenium - –ø–∞—Ä—Å–∏—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è"""

import requests
from bs4 import BeautifulSoup
import json
import pandas as pd
import re
from datetime import datetime

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
URL = "https://labirintdoors.ru/katalog2"
HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}

print("üöÄ –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä –õ–∞–±–∏—Ä–∏–Ω—Ç\n")
print(f"üìç URL: {URL}\n")

# –ó–∞–≥—Ä—É–∑–∫–∞
response = requests.get(URL, headers=HEADERS)
print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(response.content)} bytes)\n")

soup = BeautifulSoup(response.content, 'lxml')

# –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫
all_links = soup.find_all('a', href=True)
print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(all_links)}\n")

doors = []

for link in all_links:
    text = link.get_text(strip=True)
    href = link['href']
    
    # –§–∏–ª—å—Ç—Ä: –∏—â–µ–º —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ —Å –¥–≤–µ—Ä—è–º–∏
    if not text or len(text) < 10:
        continue
    
    keywords = ['–≤—Ö–æ–¥–Ω', '–¥–≤–µ—Ä', '–ª–∞–±–∏—Ä–∏–Ω—Ç', 'labirint', '—Ä—É–±']
    if not any(kw in text.lower() for kw in keywords):
        continue
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã
    price_match = re.search(r'(\d+[\s\d]+)\s*—Ä—É–±', text)
    price = int(price_match.group(1).replace(' ', '')) if price_match else None
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    if any(w in text for w in ['LEOLAB', 'SKYLAB', 'EVOLAB']):
        category = '–ù–æ–≤–∏–Ω–∫–∏ 2025'
    elif any(w in text for w in ['PIANO', 'ROYAL', 'ISSIDA', 'STORM']):
        category = '–•–∏—Ç—ã –ø—Ä–æ–¥–∞–∂'
    elif any(w in text.lower() for w in ['—Ç–µ—Ä–º–æ—Ä–∞–∑—Ä—ã–≤', 'nord', 'tundra']):
        category = '–° —Ç–µ—Ä–º–æ—Ä–∞–∑—Ä—ã–≤–æ–º'
    elif any(w in text for w in ['WHITE', 'VERSAL', '–±–µ–ª—ã–µ']):
        category = '–ë–µ–ª—ã–µ –¥–≤–µ—Ä–∏'
    else:
        category = '–û—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Ç–∞–ª–æ–≥'
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = link.find('img')
    image = None
    if img:
        image = img.get('src') or img.get('data-src')
        if image and not image.startswith('http'):
            image = f"https://labirintdoors.ru{image}"
    
    door = {
        'name': text,
        'price': price,
        'url': href if href.startswith('http') else f"https://labirintdoors.ru{href}",
        'category': category,
        'image': image
    }
    
    doors.append(door)

print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–≤–µ—Ä–µ–π: {len(doors)}\n")

if doors:
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("="*60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*60)
    print(f"üì¶ –í—Å–µ–≥–æ: {len(doors)}")
    
    prices = [d['price'] for d in doors if d['price']]
    if prices:
        print(f"üí∞ –ú–∏–Ω: {min(prices):,} ‚ÇΩ")
        print(f"üí∞ –ú–∞–∫—Å: {max(prices):,} ‚ÇΩ")
        print(f"üí∞ –°—Ä–µ–¥–Ω—è—è: {sum(prices)//len(prices):,} ‚ÇΩ")
    
    cats = {}
    for d in doors:
        cat = d['category']
        cats[cat] = cats.get(cat, 0) + 1
    
    print(f"\nüìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
    for cat, cnt in sorted(cats.items(), key=lambda x: x[1], reverse=True):
        print(f"   {cat}: {cnt}")
    print("="*60 + "\n")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # JSON
    with open(f'labirint_{ts}.json', 'w', encoding='utf-8') as f:
        json.dump(doors, f, ensure_ascii=False, indent=2)
    print(f"üíæ JSON: labirint_{ts}.json")
    
    # CSV
    df = pd.DataFrame(doors)
    df.to_csv(f'labirint_{ts}.csv', index=False, encoding='utf-8-sig')
    print(f"üíæ CSV: labirint_{ts}.csv")
    
    # Excel
    df.to_excel(f'labirint_{ts}.xlsx', index=False)
    print(f"üíæ Excel: labirint_{ts}.xlsx")
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
else:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ")
