#!/usr/bin/env python3
"""–ü–∞—Ä—Å–µ—Ä —Å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""

import requests
from bs4 import BeautifulSoup
import json
import pandas as pd
import re
from datetime import datetime
from pathlib import Path
import time
from urllib.parse import urljoin

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
URL = "https://labirintdoors.ru/katalog2"
HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}
IMAGES_DIR = Path('images')

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
IMAGES_DIR.mkdir(exist_ok=True)

print("üöÄ –ü–∞—Ä—Å–µ—Ä –õ–∞–±–∏—Ä–∏–Ω—Ç —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n")
print(f"üìç URL: {URL}")
print(f"üìÅ –ü–∞–ø–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {IMAGES_DIR}\n")

# –§—É–Ω–∫—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def download_image(url, filename):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ"""
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code == 200:
            filepath = IMAGES_DIR / filename
            with open(filepath, 'wb') as f:
                f.write(response.content)
            return str(filepath)
        else:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status_code}")
            return None
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
response = requests.get(URL, headers=HEADERS)
print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(response.content)} bytes)\n")

soup = BeautifulSoup(response.content, 'lxml')

# –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫
all_links = soup.find_all('a', href=True)
print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(all_links)}\n")

doors = []
image_counter = 0

print("üì∏ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n")

for idx, link in enumerate(all_links):
    text = link.get_text(strip=True)
    href = link['href']
    
    # –§–∏–ª—å—Ç—Ä: –∏—â–µ–º —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ —Å –¥–≤–µ—Ä—è–º–∏
    if not text or len(text) < 10:
        continue
    
    keywords = ['–≤—Ö–æ–¥–Ω', '–¥–≤–µ—Ä', '–ª–∞–±–∏—Ä–∏–Ω—Ç', 'labirint', '—Ä—É–±']
    if not any(kw in text.lower() for kw in keywords):
        continue
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã
    price_match = re.search(r'(\d+[\s\d]+)\s*—Ä—É–±', text)
    price = int(price_match.group(1).replace(' ', '')) if price_match else None
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    if any(w in text for w in ['LEOLAB', 'SKYLAB', 'EVOLAB']):
        category = '–ù–æ–≤–∏–Ω–∫–∏ 2025'
    elif any(w in text for w in ['PIANO', 'ROYAL', 'ISSIDA', 'STORM']):
        category = '–•–∏—Ç—ã –ø—Ä–æ–¥–∞–∂'
    elif any(w in text.lower() for w in ['—Ç–µ—Ä–º–æ—Ä–∞–∑—Ä—ã–≤', 'nord', 'tundra']):
        category = '–° —Ç–µ—Ä–º–æ—Ä–∞–∑—Ä—ã–≤–æ–º'
    elif any(w in text for w in ['WHITE', 'VERSAL', '–±–µ–ª—ã–µ']):
        category = '–ë–µ–ª—ã–µ –¥–≤–µ—Ä–∏'
    else:
        category = '–û—Å–Ω–æ–≤–Ω–æ–π –∫–∞—Ç–∞–ª–æ–≥'
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = link.find('img')
    image_url = None
    local_image = None
    
    if img:
        image_url = img.get('src') or img.get('data-src')
        if image_url:
            # –ü–æ–ª–Ω—ã–π URL
            if not image_url.startswith('http'):
                image_url = urljoin(URL, image_url)
            
            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_counter += 1
            filename = f"door_{image_counter:04d}.jpg"
            print(f"   üì• [{image_counter}] –ó–∞–≥—Ä—É–∂–∞—é: {filename}")
            
            local_image = download_image(image_url, filename)
            
            if local_image:
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {local_image}")
            
            time.sleep(0.3)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    door = {
        'name': text,
        'price': price,
        'url': href if href.startswith('http') else urljoin(URL, href),
        'category': category,
        'image': local_image or image_url,
        'image_url': image_url
    }
    
    doors.append(door)

print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–≤–µ—Ä–µ–π: {len(doors)}")
print(f"üì∏ –°–∫–∞—á–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_counter}\n")

if doors:
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("="*60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*60)
    print(f"üì¶ –í—Å–µ–≥–æ: {len(doors)}")
    
    prices = [d['price'] for d in doors if d['price']]
    if prices:
        print(f"üí∞ –ú–∏–Ω: {min(prices):,} ‚ÇΩ")
        print(f"üí∞ –ú–∞–∫—Å: {max(prices):,} ‚ÇΩ")
        print(f"üí∞ –°—Ä–µ–¥–Ω—è—è: {sum(prices)//len(prices):,} ‚ÇΩ")
    
    cats = {}
    for d in doors:
        cat = d['category']
        cats[cat] = cats.get(cat, 0) + 1
    
    print(f"\nüìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
    for cat, cnt in sorted(cats.items(), key=lambda x: x[1], reverse=True):
        print(f"   {cat}: {cnt}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    with_images = len([d for d in doors if d.get('image')])
    print(f"\nüì∏ –° –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {with_images}/{len(doors)} ({with_images*100//len(doors)}%)")
    
    print("="*60 + "\n")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # JSON
    with open(f'labirint_{ts}.json', 'w', encoding='utf-8') as f:
        json.dump(doors, f, ensure_ascii=False, indent=2)
    print(f"üíæ JSON: labirint_{ts}.json")
    
    # CSV
    df = pd.DataFrame(doors)
    df.to_csv(f'labirint_{ts}.csv', index=False, encoding='utf-8-sig')
    print(f"üíæ CSV: labirint_{ts}.csv")
    
    # Excel
    df.to_excel(f'labirint_{ts}.xlsx', index=False)
    print(f"üíæ Excel: labirint_{ts}.xlsx")
    
    print(f"\nüìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {IMAGES_DIR}/")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(list(IMAGES_DIR.glob('*.jpg')))}")
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
else:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ")
